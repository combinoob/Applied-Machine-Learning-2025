{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load the prepared data splits\"\"\"\n",
    "    train = pd.read_csv('train.csv')\n",
    "    validation = pd.read_csv('validation.csv')\n",
    "    test = pd.read_csv('test.csv')\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nan_data(data):\n",
    "    \"\"\"Handling NaN values in text data\"\"\"\n",
    "    data = data.copy()\n",
    "    data['message'] = data['message'].fillna('')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_data):\n",
    "    \"\"\"Fit a model on training data\"\"\"\n",
    "    # Handling NaNs\n",
    "    train_data = handle_nan_data(train_data)\n",
    "    \n",
    "    # Create and fit TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train = vectorizer.fit_transform(train_data['message'])\n",
    "    y_train = train_data['label']\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, vectorizer, data):\n",
    "    \"\"\"Score a model on given data\"\"\"\n",
    "    # Clean text data\n",
    "    data = handle_nan_data(data)\n",
    "    X = vectorizer.transform(data['message'])\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Evaluate model predictions with comprehensive metrics\"\"\"\n",
    "    print(f\"\\nEvaluation on {dataset_name} dataset:\")\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Print all metrics\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision (spam): {report['1']['precision']:.4f}\")\n",
    "    print(f\"Recall (spam): {report['1']['recall']:.4f}\")\n",
    "    print(f\"F1-score (spam): {report['1']['f1-score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    # Return F1-score for spam class\n",
    "    return report['1']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, param_grid, train_data, validation_data):\n",
    "    \"\"\"Fine-tune model hyperparameters using the validation set\"\"\"\n",
    "    # Handle NaN values\n",
    "    train_data = handle_nan_data(train_data)\n",
    "    validation_data = handle_nan_data(validation_data)\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train = vectorizer.fit_transform(train_data['message'])\n",
    "    y_train = train_data['label']\n",
    "    \n",
    "    X_val = vectorizer.transform(validation_data['message'])\n",
    "    y_val = validation_data['label']\n",
    "    \n",
    "    # Perform grid search using validation set with F1 score as metric\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the best model on validation data\n",
    "    val_pred = best_model.predict(X_val)\n",
    "    val_f1 = evaluate_predictions(y_val, val_pred, \"Validation\")\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Validation F1-score: {val_f1:.4f}\")\n",
    "    \n",
    "    return best_model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(train_data, validation_data, test_data):\n",
    "    \"\"\"Train and evaluate three benchmark models with hyperparameter tuning\"\"\"\n",
    "    # Initialize models and their hyperparameter grids\n",
    "    models = {\n",
    "        'Naive Bayes': (MultinomialNB(), {'alpha': [0.1, 0.5, 1.0]}),\n",
    "        'Linear SVM': (LinearSVC(random_state=42), {'C': [0.01, 0.1, 1, 10]}),\n",
    "        'Random Forest': (RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "                          {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]})\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for name, (model, param_grid) in models.items():\n",
    "        print(f\"\\nFine-tuning {name}...\")\n",
    "\n",
    "        # Fine-tune model using validation set\n",
    "        best_model, vectorizer = fine_tune_model(model, param_grid, train_data, validation_data)\n",
    "        \n",
    "        # Score and evaluate on test data\n",
    "        test_pred = score_model(best_model, vectorizer, test_data)\n",
    "        test_f1 = evaluate_predictions(test_data['label'], test_pred, f\"Test ({name})\")\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': best_model,\n",
    "            'vectorizer': vectorizer,\n",
    "            'f1_score': test_f1\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} Test F1-score: {test_f1:.4f}\")\n",
    "    \n",
    "    # Select best model based on F1-score\n",
    "    best_model_name = max(results.items(), key=lambda x: x[1]['f1_score'])[0]\n",
    "    print(f\"\\nBest model: {best_model_name} (F1-score: {results[best_model_name]['f1_score']:.4f})\")\n",
    "    \n",
    "    return results[best_model_name]['model'], results[best_model_name]['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning Naive Bayes...\n",
      "\n",
      "Evaluation on Validation dataset:\n",
      "Accuracy: 0.9848\n",
      "Precision (spam): 0.9854\n",
      "Recall (spam): 0.9000\n",
      "F1-score (spam): 0.9408\n",
      "\n",
      "Confusion Matrix:\n",
      "[[963   2]\n",
      " [ 15 135]]\n",
      "Best parameters: {'alpha': 0.1}\n",
      "Validation F1-score: 0.9408\n",
      "\n",
      "Evaluation on Test (Naive Bayes) dataset:\n",
      "Accuracy: 0.9785\n",
      "Precision (spam): 0.9921\n",
      "Recall (spam): 0.8456\n",
      "F1-score (spam): 0.9130\n",
      "\n",
      "Confusion Matrix:\n",
      "[[965   1]\n",
      " [ 23 126]]\n",
      "Naive Bayes Test F1-score: 0.9130\n",
      "\n",
      "Fine-tuning Linear SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nirjhar Nath\\anaconda3\\New folder\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on Validation dataset:\n",
      "Accuracy: 0.9758\n",
      "Precision (spam): 0.9424\n",
      "Recall (spam): 0.8733\n",
      "F1-score (spam): 0.9066\n",
      "\n",
      "Confusion Matrix:\n",
      "[[957   8]\n",
      " [ 19 131]]\n",
      "Best parameters: {'C': 10}\n",
      "Validation F1-score: 0.9066\n",
      "\n",
      "Evaluation on Test (Linear SVM) dataset:\n",
      "Accuracy: 0.9830\n",
      "Precision (spam): 0.9710\n",
      "Recall (spam): 0.8993\n",
      "F1-score (spam): 0.9338\n",
      "\n",
      "Confusion Matrix:\n",
      "[[962   4]\n",
      " [ 15 134]]\n",
      "Linear SVM Test F1-score: 0.9338\n",
      "\n",
      "Fine-tuning Random Forest...\n",
      "\n",
      "Evaluation on Validation dataset:\n",
      "Accuracy: 0.9695\n",
      "Precision (spam): 1.0000\n",
      "Recall (spam): 0.7733\n",
      "F1-score (spam): 0.8722\n",
      "\n",
      "Confusion Matrix:\n",
      "[[965   0]\n",
      " [ 34 116]]\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "Validation F1-score: 0.8722\n",
      "\n",
      "Evaluation on Test (Random Forest) dataset:\n",
      "Accuracy: 0.9668\n",
      "Precision (spam): 1.0000\n",
      "Recall (spam): 0.7517\n",
      "F1-score (spam): 0.8582\n",
      "\n",
      "Confusion Matrix:\n",
      "[[966   0]\n",
      " [ 37 112]]\n",
      "Random Forest Test F1-score: 0.8582\n",
      "\n",
      "Best model: Linear SVM (F1-score: 0.9338)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_data, validation_data, test_data = load_data()\n",
    "    best_model, best_vectorizer = benchmark_models(train_data, validation_data, test_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that Linear SVM is the bes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
